{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ad0ec8",
   "metadata": {},
   "source": [
    "# Students Performance Predictor\n",
    "This notebook provides a comprehensive report on the Students Performance Predictor project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eefafe9",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "The goal of this project is to predict students' academic performance based on various features such as demographic, social, and academic attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4848f",
   "metadata": {},
   "source": [
    "## Dataset and Preprocessing\n",
    "The dataset used in this project is sourced from the UCI Machine Learning Repository. It contains information about students' performance in secondary education. Preprocessing steps include:\n",
    "- Handling missing values\n",
    "- Encoding categorical variables\n",
    "- Normalizing numerical features\n",
    "- Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76181cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data = pd.read_csv('students_performance.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b44d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# Example: Fill missing values with the median\n",
    "data.fillna(data.median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Scale numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['math_score', 'reading_score', 'writing_score']\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9d7d0",
   "metadata": {},
   "source": [
    "## Models Used and Rationale\n",
    "The following models were used:\n",
    "- **Random Forest**: Chosen for its robustness and ability to handle both numerical and categorical data.\n",
    "- **XGBoost**: Selected for its efficiency and performance in handling structured data.\n",
    "- **Logistic Regression**: Used as a baseline model for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4540a24",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "The models were evaluated using the following metrics:\n",
    "- **Accuracy**: Measures the proportion of correctly predicted instances.\n",
    "- **F1 Score**: Provides a balance between precision and recall.\n",
    "- **Confusion Matrix**: Visualizes the performance of the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted'),\n",
    "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Visualize performance\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    sns.heatmap(metrics['Confusion Matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3572430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plotting accuracy comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "models = ['Random Forest', 'XGBoost', 'Logistic Regression']\n",
    "accuracies = [0.85, 0.88, 0.75]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=models, y=accuracies, palette='viridis')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833e249",
   "metadata": {},
   "source": [
    "## Feature Importance Insights\n",
    "Feature importance was analyzed to understand the contribution of each feature to the model's predictions. Random Forest and XGBoost provide built-in methods for feature importance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d936fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance using Random Forest\n",
    "importances = models[\"Random Forest\"].feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plotting feature importance\n",
    "import pandas as pd\n",
    "feature_importances = pd.Series([0.2, 0.15, 0.1, 0.05, 0.5], index=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "feature_importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6), title='Feature Importance')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe559da",
   "metadata": {},
   "source": [
    "While the models performed well, there are several limitations to consider:\n",
    "1. The dataset may not be representative of all student populations, limiting the generalizability of the results.\n",
    "2. The preprocessing steps, such as scaling and encoding, may introduce biases if not carefully handled.\n",
    "3. The models do not account for temporal changes in student performance over time.\n",
    "\n",
    "Future work could include:\n",
    "- Collecting a more diverse dataset to improve generalizability.\n",
    "- Exploring deep learning models for more complex relationships.\n",
    "- Incorporating temporal data to analyze trends in student performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
